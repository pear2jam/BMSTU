% Лабораторная работа № 1.5. Порождение лексического анализатора с помощью flex
% 18 июня 2024 г.
% Наумов Сергей ИУ9-62Б

# Цель работы
Целью данной работы является изучение генератора лексических анализаторов flex.

# Индивидуальный вариант

* Числовые литералы: знак «0» либо последовательности знаков «1».
* Строковые литералы: регулярные строки — ограничены двойными кавычками,
могут содержать escape-последовательности «\"», «\t», «\n», не пересекают
границы строк текста; буквальные строки — начинаются на «@"», заканчиваются
на двойную кавычку, пересекают границы строк текста, для включения двойной
кавычки она удваивается.

# Реализация
Обозначим задачу:
Требуется воспользоваться генератором лексических анализаторов flex для порождения 
лексического анализатора на языке C/C++
Полученный лексер должен выводить распознанные лексемы из файла из входного потока
Входной файл может содержать ошибки, которые лексер должен 'ловить' и возвращать
сообщение с указанием на координаты, после чего восстанавливаться

Flex - это инструмент для генерации лексических анализаторов. Основное преимущество
использования Flex - это автоматизация создания кода для лексера, что упрощает работу
и сокращает её время

Подключение библиотек, и определение массив токенов, который будет использоваться вывода их названий
Здесь пустая строка соотвествует EOP
Также строка `%option noyywrap bison-bridge bison-locations` выполняет несколько важных функций:

* noyywrap: Эта опция указывает Flex, что не нужно ожидать функцию `yywrap()`.
  Как правило, `yywrap()` используется для обработки нескольких файлов ввода, но
  этот лексический анализатор работает только с одним файлом, так что эта функция
  не требуется.
  Отключение `yywrap` упрощает код и может немного ускорить работу лексера.

* bison-bridge: Эта опция используется для того, чтобы обеспечить совместимость с Bison,
  если он как здесь используете его вместе с Flex.
  Она позволяет передавать информацию о лексемах из Flex в Bison через специальную
  структуру `yylval`, которая передается как параметр функции `yylex()`.

* bison-locations: Также как и `bison-bridge`, обеспечивает передачу информации
  о местоположении лексем из Flex в Bison.
  Это делается через структуру `YYLTYPE`, которая также передается
  как параметр функции `yylex()`.

```с++
%option noyywrap bison-bridge bison-locations

%{
#include <iostream>
#include <regex>
#include <string>
#include <new>
#include <array>
%}

%{
const std::string token_names[] = {"", "NUMBER", "STRING", "ERROR"};
```

В следующем блоке определяются структуры Token, LexPos и Source
для хранения информации о токенах и их позициях в тексте. 
Также объявляются вспомогательные функции для вывода информации и 
обработки исключений.

Здесь cons - это переменная, которая используется в работе с
пересекающимися строками.
Также объявляются вспомогательные cur и begin_pos

```c++
int cons = 0;

struct Token {
    long tok_id; 
    std::string res;
    Token() : tok_id(0), res("") {}
};

struct LexPos {
    int line, pos, tok_ind;
};

struct Source {
    LexPos begin, end;
};

LexPos cur;
LexPos begin_pos;

void PositionStr(const LexPos& p) {
    std::cout << "Line: " << p.line << ", LexPos: " << p.pos << std::endl;
}

void SourceStr(const Source& f) {
    std::cout << "Source begin - ";
    PositionStr(f.begin);
    std::cout << ", Source End - ";
    PositionStr(f.end);
    std::cout << std::endl;
}

void Exception(const std::string& msg, const std::string& s) {
    std::cout << "Error occured at:";
    PositionStr(begin_pos);
    std::cout << ": " << msg << " - Found: \"" << s << "\"" << std::endl;
}

void ExceptionDebug(const std::string& msg) {PositionStr(begin_pos);}

typedef Source YYLTYPE;
typedef Token YYSTYPE;

void initialize_scanner(const char* program) {
    cons = 0;
    cur.line = 1;
    cur.pos = 1;
    cur.tok_ind = 0;
    yy_scan_string(program);
}

```
В следующем блоке я устанавливаю опции Flex и 
объявляю правила для распознавания числовых и строковых литералов, 
а также для обработки ошибок.

* tok_num: Правило `tok_num 0|(1)+` распознает числовые литералы, которые
  являются либо нулем, либо последовательностью одной или более единиц.
  Когда такой литерал распознается, значение `yytext` (текст, соответствующий лексеме)
  преобразуется в целое число с помощью функции `std::atoi` и сохраняется в
  `yylval->tok_id`, после чего функция возвращает токен с идентификатором `1` (NUMBER)

* Состояния LITERAL и STRING: Используются два начальных состояния `%x LITERAL STRING`
  для различения контекстов строковых и числовых литералов.

* Обработка кавычек**:
  
   - При встрече с символом кавычки (`\"`) в начальном состоянии, лексер
     переходит в состояние `STRING`, инициализирует `yylval->res` пустой
     строкой и устанавливает флаг `cons` в `1`.
   - В состоянии `STRING`, при встрече с символом кавычки, лексер возвращается
     в начальное состояние и возвращает токен с идентификатором `2`.
   - Аналогично, в состоянии `LITERAL`, при встрече с символом кавычки,
     лексер также возвращается в начальное состояние и возвращает токен `2`.

* Обработка специальных символов:

   - В состоянии `STRING`, символ новой строки (`\n`) вызывает функцию `Exception`
     с сообщением об ошибке, после чего лексер возвращается в начальное состояние.
   - В состоянии `LITERAL`, символ новой строки добавляется в `yylval->res`.
   - Экранированные последовательности `\\n`, `\\t`, `\\\"` в состоянии `STRING`
     добавляются в `yylval->res` в виде соответствующих символов.

* Обработка конца файла (EOF):
  
   - В состояниях `LITERAL` и `STRING`, если встречается конец файла (`<<EOF>>`),
     вызывается функция `Exception` с сообщением об ошибке, указывающим на
     неожиданный конец файла, и лексер возвращается в начальное состояние.
   - В начальном состоянии, при встрече с концом файла, функция `yylex()`
     возвращает `0`, сигнализируя о завершении работы лексера.

* Дополнительные правила**:
  
   - Символ `@` с последующей кавычкой (`@\"`) инициализирует `yylval->res`
     и переводит лексер в состояние `LITERAL`.
   - В состоянии `LITERAL`, двойная кавычка (`\"\"`) добавляется в `yylval->res`.
   - Любой другой символ в состояниях `LITERAL` и `STRING` добавляется в `yylval->res`.
   - Любой символ в начальном состоянии, не соответствующий другим правилам,
     вызывает функцию `Exception` с сообщением об ошибке.


```с++
tok_num 0|(1)+

%x LITERAL STRING
%%


<LITERAL>\" {
    BEGIN(0);
    return 2;
}

<STRING>\" {
    BEGIN(0);
    return 2;
}

\" {
    yylval->res = "";
    BEGIN(STRING);
    cons = 1;
}

<STRING>\n {
    Exception("Unknown symbol", "\\n");
    BEGIN(0);
}

<LITERAL>\n {
    yylval->res.append("\n");
    cons = 1;
}

<STRING>\\n {
    yylval->res.append("\n");
    cons = 1;
}

[\n]+

<STRING>\\t {
    yylval->res.append("\t");
    cons = 1;
}

[\t]+

<STRING>\\\" {
    yylval->res.append("\"");
    cons = 1;
}

<LITERAL><<EOF>>  {
    Exception("EOF found, \" Expected;", "EOF");
    BEGIN(0);
}

<STRING><<EOF>>  {
    Exception("EOF found, \" Expected;", "EOF");
    BEGIN(0);
}
<<EOF>> return 0;

@\" {
    yylval->res = "";
    BEGIN(LITERAL);
    cons = 1;
}

<LITERAL>\"\" {
    yylval->res.append("\"");
    cons = 1;
}

<LITERAL>. {
    yylval->res.append(std::string(1, yytext[0]));
    cons = 1;
}

<STRING>. {
    yylval->res.append(std::string(1, yytext[0]));
    cons = 1;
}

. {
    Exception("Unknown symbol", std::string(1, yytext[0]));
}

{tok_id} {
    yylval->tok_id = std::atoi(yytext);
    return 1;
}

%%
```

Главная функция main вызывает функцию processFile, которая 
отвечает за чтение файла, инициализацию сканера и обработку токенов.

```c++
int processFile() {
    Token currentToken;
    Source tokenSource;
    FILE* inputFile;
    char* fileBuffer;
    
    inputFile = std::fopen("test1.txt", "r");
    std::fseek(inputFile, 0, SEEK_END);
    long fileSize = std::ftell(inputFile);
    std::rewind(inputFile);
    
    fileBuffer = new char[fileSize + 1];
    std::fread(fileBuffer, sizeof(char), fileSize, inputFile);
    fileBuffer[fileSize] = '\0';

    initialize_scanner(fileBuffer);
    
    YYSTYPE tokenValue;
    YYLTYPE tokenCoords;
    int tag = yylex(&tokenValue, &tokenCoords);

    while (tag != 0) {
        std::cout << token_names[tag];
        tag = yylex(&tokenValue, &tokenCoords);
    }

    delete[] fileBuffer;
    std::fclose(inputFile);

    return 0;
}

int main() {
    processFile();
}
```



# Тестирование
Пользовательская программа

```
0 111
"abc\" \ \t \nstring"
@"abc
dfe"
"a
b"
111
```

Вывод лексера

```
NUM(1,1)-(1,2): 0
NUM(1,3)-(1,6): 111
STRING(2,1)-(2,22): abc" \ 	 
string
STRING(3,1)-(4,5): abc
dfe
Error(5,3): ERROR unknown symbol "\n"
Error(6,1): ERROR unknown symbol "b"
Error(6,3): ERROR unknown symbol "\n"
NUM(7,1)-(7,4): 111
```

Лексический анализ прошел корректно - распознаны все лексемы языка,
была выведена ошибка, после чего анализатор восстановился

# Вывод

В ходе выполнения лабораторной работы по порождению лексического анализатора с помощью Flex,
был достигнуты результаты и получен ценный опыт в области лексического анализа.
Приведу некоторые моменты и выводы из работы:

* Повторение C++ : Было просмотрено и усвоено много материала по C++, так как
  пришлось вспоминать этот язык, в процессе разработки я сталкивался с большим
  количеством ошибок связанных с работой языка, которые исправлялись поиском решений
  в интернете, документациях и лекциях.
  Это развивает навык быстро разобраться в новом/плохо знакомом языке и использовать
  его в своей работе, что может быть очень полезно для дальнейшей работы.

* Освоение Flex : Был успешно освоен генератор лексических анализаторов Flex,
  что позволило автоматизировать процесс создания лексера для языков C/C++.
  Это улучшило понимание механизмов работы лексических анализаторов.

* Работа с числовыми и строковыми литералами: Реализована поддержка распознавания
  числовых литералов, представленных знаком "0" или последовательностями знаков "1",
  а также строковых литералов с учетом escape-последовательностей и строк,
  пересекающих границы текста.

* Обработка ошибок: Было уделено внимание механизму обработки ошибок. Лексер настроен
  на 'ловлю' ошибок и возвращение сообщений с указанием координат ошибки,
  что позволяет быстро локализовать и исправить проблемы в коде.

* Интересные моменты реализации: Управление состояниями Flex: Использование макросов
  BEGIN и состояний %x для переключения между контекстами распознавания строковых и
  числовых литералов.
  
* Работа с документацией Flex: в процессе разработки, часто приходилось обращаться к
  документации Flex (https://github.com/westes/flex/blob/master/doc)
  Например при реализации обработки escape-последовательностей заглянул изучить
  спецификацию символьных классов в Flex, или например для корректной обработки EOF в
  литералах были использованы примеры из документации, позволяющие правильно завершать
  работу лексера при достижении конца файла.

* Модульность и расширяемость кода: Созданный лексический анализатор обладает модульной
  структурой, что облегчает его дальнейшее расширение и интеграцию в потенциальные проекты.

В результате выполнения лабораторной работы были усвоены ключевые аспекты создания
лексических анализаторов, получен опыт работы с Flex и его документацией,
а также развиты навыки программирования и отладки кода. Эти знания и умения 
будут полезны в будущих проектах и при дальнейшем изучении компиляторов.
